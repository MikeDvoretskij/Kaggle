{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "## Overview\n",
    "Примеры в конкурсном наборе данных представлены бинарной классификацией того, является ли данная малая молекула связывающей для одной из трех целевых белковых молекул. Данные были собраны с использованием технологии химических библиотек, закодированных ДНК (DEL).\n",
    "\n",
    "Химия представлена с помощью SMILES (упрощенная система записи молекулярных входных линий), а метки - как бинарные классификации связывания, по одной для каждой из трех целевых белковых молекул.\n",
    "\n",
    "## Files\n",
    "- **[train/test].[csv/parquet]** - Тренировочные или тестовые данные, доступные в форматах csv и parquet.\n",
    "  - **id** - Уникальный идентификатор example_id, используемый для идентификации пары молекула-целевая белковая молекула.\n",
    "  - **buildingblock1_smiles** - Структура первого строительного блока в формате SMILES.\n",
    "  - **buildingblock2_smiles** - Структура второго строительного блока в формате SMILES.\n",
    "  - **buildingblock3_smiles** - Структура третьего строительного блока в формате SMILES.\n",
    "  - **molecule_smiles** - Структура полностью собранной молекулы в формате SMILES. Включает три строительных блока и триазиновое ядро. В качестве замены для ДНК-связующего звена используется [Dy].\n",
    "  - **protein_name** - Имя целевого белка.\n",
    "  - **binds** - Целевой столбец. Бинарная метка, указывающая, связывается ли молекула с белком. Недоступно для тестового набора данных.\n",
    "- **sample_submission.csv** - Образец файла отправки в правильном формате.\n",
    "\n",
    "## Competition data\n",
    "Все данные были сгенерированы внутри компании Leash Biosciences. Мы предоставляем примерно 98 миллионов тренировочных примеров на белок, 200 тысяч примеров для валидации на белок и 360 тысяч тестовых молекул на белок. Чтобы проверить обобщаемость, в тестовом наборе содержатся строительные блоки, которых нет в тренировочном наборе. Эти наборы данных сильно несбалансированы: примерно 0.5% примеров классифицируются как связывающие; мы использовали 3 раунда отбора в тройных повторениях для экспериментального выявления связывающих молекул. После конкурса Leash предоставит все данные для будущего использования (3 цели * 3 раунда отбора * 3 повторения * 133 миллиона молекул, или 3.6 миллиарда измерений).\n",
    "\n",
    "## Targets\n",
    "Белки кодируются в геноме, и названия генов, кодирующих эти белки, обычно присваиваются их первооткрывателями и регулируются Комитетом по номенклатуре генов Хьюго. Белковые продукты этих генов иногда могут иметь разные названия, часто из-за истории их открытия.\n",
    "\n",
    "Мы протестировали три целевых белка для этого конкурса.\n",
    "\n",
    "### EPHX2 (sEH)\n",
    "Первая цель, эпоксидгидролаза 2, кодируется генетическим локусом EPHX2, и ее белковый продукт обычно называется «растворимая эпоксидгидролаза» или сокращенно sEH. Гидролазы - это ферменты, катализирующие определенные химические реакции, и EPHX2/sEH также гидролизует некоторые фосфатные группы. EPHX2/sEH является потенциальной мишенью для лекарств от высокого кровяного давления и прогрессирования диабета, и малые молекулы, ингибирующие EPHX2/sEH из предыдущих DEL-исследований, дошли до клинических испытаний.\n",
    "\n",
    "EPHX2/sEH также был протестирован с использованием DEL и результаты были предсказаны с помощью методов машинного обучения, но данные скрининга не были опубликованы. Мы включили EPHX2/sEH, чтобы участники могли проверить производительность моделей, сравнив с ранее опубликованными результатами.\n",
    "\n",
    "Мы протестировали EPHX2/sEH, приобретенный у Cayman Chemical, коммерческого поставщика продуктов для наук о жизни. Для участников, желающих включить структурную информацию о белке в свои отправки, аминокислотная последовательность составляет позиции 2-555 из UniProt записи P34913, кристаллическая структура представлена в PDB записи 3i28, а предсказанная структура доступна в AlphaFold2 записи 34913. Дополнительные кристаллические структуры EPHX2/sEH с лигандами можно найти в PDB.\n",
    "\n",
    "### BRD4\n",
    "Вторая цель, бромодомен 4, кодируется локусом BRD4, и его белковый продукт также называется BRD4. Бромодомены связываются с белковыми шпулями в ядре, вокруг которых обвивается ДНК (называются гистонами), и влияют на вероятность транскрипции находящейся рядом ДНК, производя новые генетические продукты. Бромодомены играют роль в прогрессировании рака, и было обнаружено несколько препаратов, ингибирующих их активность.\n",
    "\n",
    "BRD4 был ранее протестирован с использованием DEL, но данные скрининга не были опубликованы. Мы включили BRD4, чтобы участники могли оценить кандидатные молекулы для онкологических показаний.\n",
    "\n",
    "Мы протестировали BRD4, приобретенный у Active Motif, коммерческого поставщика продуктов для наук о жизни. Для участников, желающих включить структурную информацию о белке в свои отправки, аминокислотная последовательность составляет позиции 44-460 из UniProt записи O60885-1, кристаллическая структура (для одного домена) представлена в PDB записи 7USK, а предсказанная структура доступна в AlphaFold2 записи O60885. Дополнительные кристаллические структуры BRD4 с лигандами можно найти в PDB.\n",
    "\n",
    "### ALB (HSA)\n",
    "Третья цель, сывороточный альбумин, кодируется локусом ALB, и его белковый продукт также называется ALB. Белковый продукт иногда сокращенно называют HSA, что означает «человеческий сывороточный альбумин». ALB, самый распространенный белок в крови, используется для создания осмотического давления (для возвращения жидкости из тканей в кровеносные сосуды) и для транспортировки множества лигандов, гормонов, жирных кислот и других веществ.\n",
    "\n",
    "Альбумин, будучи самым распространенным белком в крови, часто играет роль в поглощении кандидатных лекарств в организме и изоляции их от целевых тканей. Корректировка кандидатных лекарств для уменьшения связывания с альбумином и другими белками крови является стратегией для повышения эффективности этих лекарств.\n",
    "\n",
    "ALB был ранее протестирован с использованием DEL, но данные скрининга не были опубликованы. Мы включили ALB, чтобы участники могли создавать модели, которые могут иметь большое влияние на открытие лекарств для многих заболеваний. Способность хорошо предсказывать связывание ALB позволит разработчикам лекарств быстрее улучшать свои кандидатные малые молекулы, чем путем физического изготовления многих вариантов и их эмпирического тестирования на ALB в итеративном процессе.\n",
    "\n",
    "Мы протестировали ALB, приобретенный у Active Motif. Для участников, желающих включить структурную информацию о белке в свои отправки, аминокислотная последовательность составляет позиции 25-609 из UniProt записи P02768, кристаллическая структура представлена в PDB записи 1AO6, а предсказанная структура доступна в AlphaFold2 записи P02768. Дополнительные кристаллические структуры ALB с лигандами можно найти в PDB.\n",
    "\n",
    "## Good luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "import plotly.graph_objs as go\n",
    "tqdm.pandas()\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, Crippen\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "train_path = 'train.parquet'\n",
    "test_path = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "\n",
    "data = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 0\n",
    "                        ORDER BY random()\n",
    "                        LIMIT 10000)\n",
    "                        UNION ALL\n",
    "                        (SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 1\n",
    "                        ORDER BY random()\n",
    "                        LIMIT 10000)\"\"\").df()\n",
    "\n",
    "data.columns = [\"id\", \"block_1\", \"block_2\", \"block_3\", \"molecule\", \"protein_name\", \"binds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoded_classes = encoder.fit_transform(data[[\"protein_name\"]])\n",
    "data[encoder.get_feature_names_out()] = encoded_classes.toarray()\n",
    "del data\n",
    "del encoded_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_query = f\"\"\"\n",
    "    SELECT binds, COUNT(*) AS count\n",
    "    FROM '{train_path}'\n",
    "    GROUP BY binds\n",
    "\"\"\"\n",
    "\n",
    "class_counts = con.execute(count_query).fetchdf()\n",
    "display(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lipophisity(m):\n",
    "     lipo = Crippen.MolLogP(m)\n",
    "     return lipo\n",
    "\n",
    "def rotatable_bonds(m):\n",
    "     bounds = Descriptors.NumRotatableBonds(m)\n",
    "     return bounds\n",
    "\n",
    "def num_h_donors(m):\n",
    "    h_donors = Descriptors.NumHDonors(m)\n",
    "    return h_donors\n",
    "\n",
    "def num_h_acceptors(m):\n",
    "    h_acceptors = Descriptors.NumHAcceptors(m)\n",
    "    return h_acceptors\n",
    "\n",
    "def tpsa(m):\n",
    "    tps = Descriptors.TPSA(m)\n",
    "    return tps\n",
    "\n",
    "def refractivity(m):\n",
    "    refract = Crippen.MolMR(m)\n",
    "    return refract\n",
    "\n",
    "def generate_ecfp(molecule, radius=2, bits=1024):\n",
    "    if molecule is None:\n",
    "        return None\n",
    "    return list(AllChem.GetMorganFingerprintAsBitVect(molecule, radius, nBits=bits))\n",
    "\n",
    "def get_balanced_batch(con, train_path, limit):\n",
    "    data = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 0\n",
    "                        ORDER BY random()\n",
    "                        LIMIT {limit})\n",
    "                        UNION ALL\n",
    "                        (SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 1\n",
    "                        ORDER BY random()\n",
    "                        LIMIT {limit})\"\"\").df()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_row(row, encoder, properties):\n",
    "    mol = Chem.MolFromSmiles(row['molecule'])\n",
    "    ecfp = generate_ecfp(mol)\n",
    "    row['ecfp'] = ecfp\n",
    "    \n",
    "    encoded_classes = encoder.transform([[row[\"protein_name\"]]])\n",
    "    for feature, value in zip(encoder.get_feature_names_out(), encoded_classes.toarray()[0]):\n",
    "        row[feature] = value\n",
    "    \n",
    "    for key, func in properties.items():\n",
    "        row[f\"molecule_{key}\"] = func(mol)\n",
    "    \n",
    "    row = row.drop([\"block_1\", \"block_2\", \"block_3\", \"protein_name\", \"id\", \"molecule\"])\n",
    "    \n",
    "    return row\n",
    "\n",
    "def process_dataframe(df, encoder, properties, n_jobs=-1):\n",
    "    rows = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_row)(row, encoder, properties) for _, row in df.iterrows()\n",
    "    )\n",
    "    processed_df = pd.DataFrame(rows)\n",
    "    return processed_df\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)[:, 0]\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def update_roc_curve(model, dataloader):\n",
    "    model.eval()\n",
    "    val_outputs = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in dataloader:\n",
    "            outputs = model(batch_data)[:, 0]\n",
    "            val_outputs.extend(outputs.cpu().numpy())\n",
    "            val_labels.extend(batch_labels.cpu().numpy())\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(val_labels, val_outputs)\n",
    "    val_auc = roc_auc_score(val_labels, val_outputs)\n",
    "    \n",
    "    plt.clf()  # Очищаем текущий график\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)  # Пауза для обновления графика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {\n",
    "    \"logp\": lipophisity,\n",
    "    \"rotatable_bonds\": rotatable_bonds,\n",
    "    \"h_donors\": num_h_donors,\n",
    "    \"h_acceptors\": num_h_acceptors,\n",
    "    \"tpsa\": tpsa,\n",
    "    \"refractivity\": refractivity,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with torch.no_grad():\n",
    "            sample = torch.tensor(self.data[idx], dtype=torch.float32).to(\"cuda\")\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.float32).to(\"cuda\")\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, middle_inputs) -> None:\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.LazyLinear(middle_inputs)\n",
    "        self.fc2 = nn.LazyLinear(middle_inputs * 2)\n",
    "        self.fc3 = nn.LazyLinear(middle_inputs * 2)\n",
    "        self.fc4 = nn.LazyLinear(middle_inputs * 2)\n",
    "        self.fc5 = nn.LazyLinear(middle_inputs // 2)\n",
    "        self.out = nn.LazyLinear(1)\n",
    "\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.prelu3 = nn.PReLU()\n",
    "        self.prelu4 = nn.PReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.33)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.fc1(src)\n",
    "        src = self.dropout(src)\n",
    "        src = self.prelu1(self.fc2(src))\n",
    "        src = self.dropout(src)\n",
    "        src = self.prelu2(self.fc3(src))\n",
    "        src = self.dropout(src)\n",
    "        src = self.prelu3(self.fc4(src))\n",
    "        src = self.dropout(src)\n",
    "        src = self.prelu4(self.fc5(src))\n",
    "        src = self.out(src)\n",
    "        src = self.sigmoid(src)\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(middle_inputs=2048).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "optimazer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "citeration = nn.BCELoss().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "\n",
    "epochs = 150\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "\n",
    "    data = get_balanced_batch(con, train_path, 50_000)\n",
    "    data.columns = [\"id\", \"block_1\", \"block_2\", \"block_3\", \"molecule\", \"protein_name\", \"binds\"]\n",
    "    data = process_dataframe(data, encoder, properties, 8)\n",
    "\n",
    "    X = [ecfp + protein for ecfp, protein in zip(data['ecfp'].tolist(), data.drop(['binds', 'ecfp'], axis=1).values.tolist())]\n",
    "    y = data['binds'].tolist()\n",
    "    del data\n",
    "    \n",
    "    dataset = CustomDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=10_000, shuffle=True)\n",
    "    del X\n",
    "    del y\n",
    "    \n",
    "    if epoch % 5 != 0:\n",
    "        train(model, dataloader, citeration, optimazer)\n",
    "    else:\n",
    "        update_roc_curve(model, dataloader)\n",
    "\n",
    "    model_path = \"model_weights.pth\"\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_test in tqdm(pd.read_csv(test_path, chunksize=100_000)):\n",
    "    data_test.columns = [\"id\", \"block_1\", \"block_2\", \"block_3\", \"molecule\", \"protein_name\"]\n",
    "    id = data_test[\"id\"]\n",
    "    data_test = process_dataframe(data_test, encoder, properties, 8)\n",
    "\n",
    "    X = [ecfp + protein for ecfp, protein in zip(data_test['ecfp'].values.tolist(), data_test.drop(['ecfp'], axis=1).values.tolist())]\n",
    "    predictions = []\n",
    "\n",
    "    dataset = CustomDataset(X, [0 for i in range(len(X))])\n",
    "    dataloader = DataLoader(dataset, batch_size=10_000, shuffle=False)\n",
    "    del X\n",
    "    \n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = list(model(batch_data)[:, 0].to(\"cpu\").detach())\n",
    "            predictions += outputs\n",
    "\n",
    "    output_df = pd.DataFrame({'id': id, 'binds': predictions})\n",
    "    output_df[\"binds\"] = output_df[\"binds\"].apply(lambda x: float(x))\n",
    "    \n",
    "    output_df.to_csv(\"submission.csv\", index=False, mode='a', header=not os.path.exists(\"submission.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
